{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\"Jade\":0, \"James\":1, \"Jane\":2, \"Joel\":3, \"Jovi\":4}\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    one_hot = np.zeros((len(labels), len(class_labels)))\n",
    "    for i, label in enumerate(labels):  \n",
    "        one_hot[i, label] = 1 \n",
    "    return one_hot\n",
    "    \n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"L\") # open and converting to grayscale\n",
    "    return np.array(image, dtype=np.float32).flatten()/255 # get image pixels, make an array of the pixels and normalize \n",
    "\n",
    "def extract_images_from_folder(folder_name):\n",
    "    image_data = []\n",
    "    category_labels = []\n",
    "\n",
    "    for root, _, files in os.walk(folder_name): # root is the folder train, _ are the subdirectories\n",
    "        folder_name = os.path.basename(root) # basename extracts category/folder name \n",
    "        for name in files:\n",
    "            if name.endswith(\".png\"):\n",
    "                image_path = os.path.join(root, name)\n",
    "                image_data.append(load_image(image_path))\n",
    "                category_labels.append(class_labels[folder_name]) # assigns integer according to folder name\n",
    "    image_data = np.array(image_data)\n",
    "    category_labels = np.array(category_labels)\n",
    "    one_hot_labels = one_hot_encode(category_labels)\n",
    "\n",
    "    indices = np.random.permutation(len(image_data)) # shuffle dataset\n",
    "    return image_data[indices], one_hot_labels[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z):\n",
    "    # return np.exp(Z)/np.sum(np.exp(Z)) overflow\n",
    "    expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True)) # subtracting with largest value makes largest element zero\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
    "\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    w1 = np.random.randn(hidden_size, input_size) * 0.01 # randn normal distribution (mean=0, std=1), so values centered around 0\n",
    "    b1 = np.zeros((hidden_size, 1))\n",
    "    w2 = np.random.randn(output_size, hidden_size) * 0.01\n",
    "    b2 = np.zeros((output_size, 1))\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def forward_propagation(w1, b1, w2, b2, X):\n",
    "    Z1 = np.dot(w1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(w2, A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def back_propagation(Z1, A1, Z2, A2, w1, w2, X, Y):\n",
    "    m = Y.shape[1]\n",
    "    dZ2 = A2 - Y\n",
    "    dw2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.dot(w2.T, dZ2) * relu_derivative(Z1)\n",
    "    dw1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate):\n",
    "    w1 -= learning_rate * dw1\n",
    "    b1 -= learning_rate * db1\n",
    "    w2 -= learning_rate * dw2\n",
    "    b2 -= learning_rate * db2\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0) # returns most probable class\n",
    "\n",
    "def gradient_descent(X, Y, learning_rate, iterations):\n",
    "    input_size = X.shape[0]\n",
    "    hidden_size = 5  # number of labels\n",
    "    output_size = Y.shape[0]\n",
    "    \n",
    "    w1, b1, w2, b2 = initialize_parameters(input_size, hidden_size, output_size)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_propagation(w1, b1, w2, b2, X)\n",
    "        dw1, db1, dw2, db2 = back_propagation(Z1, A1, Z2, A2, w1, w2, X, Y)\n",
    "        w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate)\n",
    "\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "train_data, train_labels = extract_images_from_folder(\"Train\") # load dataset\n",
    "\n",
    "w1, b1, w2, b2 = gradient_descent(train_data.T, train_labels.T, 0.10, 500) # train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.30%\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(predictions, true_labels):\n",
    "    true_classes = np.argmax(true_labels, axis=1)  # convert one hot to integer labels\n",
    "    accuracy = np.mean(predictions == true_classes) * 100 \n",
    "    return accuracy\n",
    "\n",
    "test_data, test_labels = extract_images_from_folder(\"Test\")\n",
    "\n",
    "Z1, A1, Z2, A2 = forward_propagation(w1, b1, w2, b2, test_data.T)\n",
    "\n",
    "predictions = get_predictions(A2)  \n",
    "\n",
    "accuracy = compute_accuracy(predictions, test_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
